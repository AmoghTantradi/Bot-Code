{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12 lead new",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmoghTantradi/Bot-Code/blob/master/12_lead_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdJbfEfxcQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bb0926-c6a6-4ca6-e5c4-f5fdc7231b99"
      },
      "source": [
        "!pip install wfdb\r\n",
        "!pip install tensorflow\r\n",
        "!pip install autokeras\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/99/4b4749925cf4123643b512e27710bfaad4f048eba8b840c581780e2aada9/wfdb-3.2.0-py3-none-any.whl (119kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20kB 22.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2016.8.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2020.12.5)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.10.0)\n",
            "Requirement already satisfied: chardet>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.23.0)\n",
            "Collecting threadpoolctl>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3>=1.22 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.4 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.4.7)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2018.9)\n",
            "Requirement already satisfied: idna>=2.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10.0->wfdb) (1.15.0)\n",
            "Installing collected packages: threadpoolctl, wfdb\n",
            "Successfully installed threadpoolctl-2.1.0 wfdb-3.2.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (51.1.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Collecting autokeras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/12/cf698586ccc8245f08d1843dcafb65b064a2e9e2923b889dc58e1019f099/autokeras-1.0.12-py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.22.2.post1)\n",
            "Collecting keras-tuner>=1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from autokeras) (20.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0OlOHXlxq-h"
      },
      "source": [
        "import wfdb\r\n",
        "from wfdb import io, plot\r\n",
        "from collections import Counter\r\n",
        "import os, glob\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import autokeras as ak\r\n",
        "import tensorflow as tf\r\n",
        "import shutil\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLpZmPTHxmQ6"
      },
      "source": [
        "!gsutil -m cp -r gs://ptb-xl-1.0.1.physionet.org .\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66mHGG43fOQL"
      },
      "source": [
        "shutil.move('/content/drive/MyDrive/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip','/content/')\n",
        "\n",
        "!unzip /content/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip \n",
        "\n",
        "os.rename('/content/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1', 'dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8opRmniFwi8"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2fthFYkOVaY"
      },
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import VGG19\n",
        "from keras.applications import DenseNet169\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Hexj2Lyadu"
      },
      "source": [
        "import ast\r\n",
        "\r\n",
        "keys=[]\r\n",
        "\r\n",
        "def load_raw_data(df, sampling_rate, path):\r\n",
        "    if sampling_rate == 100:\r\n",
        "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\r\n",
        "    else:\r\n",
        "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\r\n",
        "    data = np.array([signal for signal, meta in data])\r\n",
        "    return data\r\n",
        "\r\n",
        "path = '/content/dataset/'\r\n",
        "sampling_rate=100\r\n",
        "\r\n",
        "# load and convert annotation data\r\n",
        "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\r\n",
        "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\r\n",
        "\r\n",
        "# Load raw signal data\r\n",
        "X = load_raw_data(Y, sampling_rate, path)\r\n",
        "\r\n",
        "# Load scp_statements.csv for diagnostic aggregation\r\n",
        "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\r\n",
        "agg_df = agg_df[agg_df.diagnostic == 1]\r\n",
        "\r\n",
        "def aggregate_diagnostic(y_dic):\r\n",
        "    tmp = []\r\n",
        "    for key in y_dic.keys():\r\n",
        "      if key=='NORM' or 'MI' in key:\r\n",
        "        if key in agg_df.index:\r\n",
        "            keys.append(key)\r\n",
        "            tmp.append(agg_df.loc[key].diagnostic_class)\r\n",
        "    return list(set(tmp))\r\n",
        "\r\n",
        "# Apply diagnostic superclass\r\n",
        "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\r\n",
        "\r\n",
        "# Split data into train and test\r\n",
        "test_fold = 10\r\n",
        "# # Train\r\n",
        "# trainX = X[np.where(Y.strat_fold != test_fold)]\r\n",
        "# trainY = Y[((Y.strat_fold != test_fold))].diagnostic_superclass\r\n",
        "# # Test\r\n",
        "# testX = X[np.where(Y.strat_fold == test_fold)]\r\n",
        "# testY = Y[Y.strat_fold == test_fold].diagnostic_superclass\r\n",
        "\r\n",
        "trainX = X[:19634]\r\n",
        "trainY = Y[:19364].diagnostic_superclass\r\n",
        "# Test\r\n",
        "testX = X[19634:]\r\n",
        "testY = Y[19634:].diagnostic_superclass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjIReRSDgoK6"
      },
      "source": [
        "X.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KrDw3WogyN6"
      },
      "source": [
        "trainX.shape, trainY.shape, testX.shape, testY.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx0bV2IihIHt"
      },
      "source": [
        "Y[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrhRzIfIegZ3"
      },
      "source": [
        "pd.concat((pd.DataFrame(trainX.reshape(19634, 12000)), pd.Series(trainY)), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyadFfoJgg0P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTUVIvNrdlHC"
      },
      "source": [
        "Counter(Y.strat_fold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9wmmlyEv9nu"
      },
      "source": [
        "Counter(keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BR4IQt5Gdpp"
      },
      "source": [
        "print(trainX.shape)\r\n",
        "print(trainY.shape)\r\n",
        "print(testX.shape)\r\n",
        "print(testY.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJeAL7caxuDf"
      },
      "source": [
        "y = []\r\n",
        "for item in trainY:\r\n",
        "  if len(item)==1:\r\n",
        "    y.append(item[0])\r\n",
        "Counter(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WqRK90WoL8f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjQ_W-wSqzDa"
      },
      "source": [
        "Counter([len(item) for item in trainY])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9inUz50Xzr6P"
      },
      "source": [
        "y_train=[]; train_inds=[]\r\n",
        "\r\n",
        "for item in trainY:\r\n",
        "  if len(item)==1:\r\n",
        "    train_inds.append(list(trainY).index(item))\r\n",
        "    y_train.append(item[0])\r\n",
        "\r\n",
        "y_test=[]; test_inds=[]\r\n",
        "\r\n",
        "for item in testY:\r\n",
        "  if len(item)==1:\r\n",
        "    test_inds.append(list(testY).index(item))\r\n",
        "    y_test.append(item[0])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqgpAZ9mP-cm"
      },
      "source": [
        "record = wfdb.rdrecord('/content/dataset/records100/00000/00001_lr')\r\n",
        "wfdb.plot_wfdb(record)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4kAkGkTRkek"
      },
      "source": [
        "plt.imshow(pd.DataFrame(X_train[0]).corr(),cmap='hot',interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VvgZsieYnEM"
      },
      "source": [
        "X_train = (trainX[train_inds]); X_test = testX[test_inds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtzOCmKNg6La"
      },
      "source": [
        "pd.concat((pd.DataFrame(trainX.reshape(19634, 12000)), pd.Series(trainY)), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nV1-Sg5hYgi"
      },
      "source": [
        "trainY.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAl-r78aP4p1"
      },
      "source": [
        "pd.DataFrame(X_train[0]).corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IlBG9pyhzxe"
      },
      "source": [
        "X_train = (trainX[train_inds].reshape(13220, 80, 50, 3))\n",
        "X_test = (testX[test_inds].reshape(1431, 80, 50, 3))\n",
        "y_train = np.array([[1,0] if x == 'NORM' else [0,1] for x in y_train])\n",
        "y_test = np.array([[1,0] if x == 'NORM' else [0,1] for x in y_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0kdYKWblWXy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD-oKviklI0F"
      },
      "source": [
        "testX[test_inds].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mafrLoop0_my"
      },
      "source": [
        "print(X_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(X_test.shape)\r\n",
        "print(y_test.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AM4REEiqF9y"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4-Cu5dGpYrC"
      },
      "source": [
        "Counter([0 if x == 'NORM' else 1 for x in y_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4mexNwoqJLE"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG_yPI02pth0"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiF5eW969sHQ"
      },
      "source": [
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(DenseNet169(\r\n",
        "    include_top=False,\r\n",
        "    pooling='avg',\r\n",
        "    weights='imagenet',\r\n",
        "    input_shape = (80, 50, 3)\r\n",
        "    ))\r\n",
        "\r\n",
        "model.add(Dense(2, activation='sigmoid'))\r\n",
        "print(model.layers)\r\n",
        "model.layers[0].trainable = False\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "# model.summary()\r\n",
        "\r\n",
        "fit_history = model.fit(\r\n",
        "    X_train[:4000], y_train[:4000],\r\n",
        "    epochs=1,\r\n",
        "    verbose=1,\r\n",
        "    #callbacks=callbacks\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qksM8n4VPVGi"
      },
      "source": [
        "predictions = (np.argmax(model.predict(X_test),axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7tJkLkam7A-"
      },
      "source": [
        "Counter(trainY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF1NSv0ZSgmf"
      },
      "source": [
        "y_hat = np.array([0 if x == 'NORM' else 1 for x in y_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cic5AMrecX8I"
      },
      "source": [
        "Counter(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uFHW2rIbTrV"
      },
      "source": [
        "np.mean(predictions==y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03H7cP5oXDF2"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOZFrWFaTbiO"
      },
      "source": [
        "for record in tqdm(range(len(X_train[1:]))):\r\n",
        "  channel0 = np.array((pd.DataFrame(pd.DataFrame(X_train[record])[0])))\r\n",
        "  channel0s = np.hstack((channel0s, channel0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5zWkP4NV5vm"
      },
      "source": [
        "pd.DataFrame(channel0s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLB-0QBPWTS3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}